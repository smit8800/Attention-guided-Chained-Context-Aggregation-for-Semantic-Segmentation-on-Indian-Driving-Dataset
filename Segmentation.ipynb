{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKpp1EzDQXDt"
   },
   "source": [
    "<pre>\n",
    "1. Download the Italian to English translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
    "\n",
    "2. You will find ita.txt file in that ZIP, you can read that data using python and preprocess that data. \n",
    "\n",
    "3. You have to implement an Encoder and Decoder architecture with Luong attention.\n",
    "\n",
    "Encoder   - with 1 layer LSTM \n",
    "Decoder   - with 1 layer LSTM\n",
    "attention - Luone attention. (Please refer the reference notebook to know more about the attention mechanisum.)\n",
    "\n",
    "4. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook). As a part of this assignment <strong>you need to create 3 models for each scoring function.</strong>\n",
    "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
    "    In model 1 you need to implemnt \"dot\" score function\n",
    "    In model 2 you need to implemnt \"general\" score function\n",
    "    In model 3 you need to implemnt \"concat\" score function\n",
    "    \n",
    "\n",
    "    <strong>Please do add the markdown titles for each model  so that we can have a better look at the code and verify.</strong>\n",
    "\n",
    "5. Using attention weights, you can plot the attention plots, please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
    "\n",
    "6. The attention layer has to be written by yourself only. The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
    "\n",
    "7. You can use any tf.Keras highlevel API's to build and train the models. Check the reference notebook for better understanding.\n",
    "\n",
    "8. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
    "\n",
    "9. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "10. Resources:\n",
    "    a. Check the reference notebook\n",
    "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
    "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
    "    \n",
    "\n",
    "Note 1:  There are many blogs on the attention mechanisum which might be misleading you, so do read the references completly and after that only please check the internet. the best things is to read the research papers and try to implement it on your own. \n",
    "\n",
    "Note 2: To complete this assignment, the reference that are mentioned will be enough.\n",
    "\n",
    "Note 3: If you are starting this assignment, you might have completed minimum of 20 assignment. If  you are still not able to implement this algorithm you might have rushed in the previous assignments with out learning much and didn't spend your time productively.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m97g-HGSJIwF"
   },
   "outputs": [],
   "source": [
    "#Referneces \n",
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "# https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "# https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/\n",
    "# https://arxiv.org/pdf/1508.04025.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NdY7zaiWZKYV",
    "outputId": "fd7b7db8-24ec-41fa-a943-7ccb68c896f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pPQAAA9bqaDI",
    "outputId": "1c20ad9d-dd3f-40fb-a30b-e99f3c510fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#loading packages\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.executing_eagerly()\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7l9y1TlZSAl"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7vYcYVBfEQ1"
   },
   "outputs": [],
   "source": [
    "# https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/\n",
    "#Normalising the text data \n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "      )\n",
    "def normalize_string(s):\n",
    "  s = unicode_to_ascii(s)\n",
    "  s = s.replace(r'.', r' .')\n",
    "  s = s.replace(r'!', r' !')\n",
    "  s = s.replace(r'?', r' ?')\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "cf4c373ea6e44c7cb5267ab731c476bf",
      "876fb3be29634e17836820d516432318",
      "b72eb119c830402091b33289ecd31b57",
      "db6f34ab19894f229a9d35b969f04cf7",
      "e9827b3313214c20b0adedf22b882961",
      "48c87962dbbf4fc89f701b4ffb6da3c0",
      "53a79102dcc3402fa588ae20cd429833",
      "dd32e8c2404f40bca1b3da96c020472f"
     ]
    },
    "colab_type": "code",
    "id": "TjM78RZeZDH2",
    "outputId": "f2aee548-2f32-4c58-a915-dac839d32801"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4c373ea6e44c7cb5267ab731c476bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Data PreProcessing\n",
    "\n",
    "file = open(r'/content/drive/My Drive/Attention Models/ita.txt', '+r')\n",
    "\n",
    "english = []\n",
    "italian = []\n",
    "output =[]\n",
    "\n",
    "for i in tqdm.tqdm_notebook(file):\n",
    "  sententce = normalize_string(str(i).split('\\t')[0])\n",
    "  english.append(sententce.split())\n",
    "  \n",
    "  sentence = normalize_string(str(i).split('\\t')[1])\n",
    "  sentence = '<start> '+sentence\n",
    "  italian.append(sentence.split())\n",
    "\n",
    "  sentence = normalize_string(str(i).split('\\t')[1])\n",
    "  sentence = sentence+' <end>'\n",
    "  output.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "KmaCV5poadGQ",
    "outputId": "36c746b8-573a-438c-e8cc-ced9321ecb8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sequences\n",
      "[[1621    1    0    0    0    0    0    0    0]\n",
      " [ 394   80    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "#Tokenization On english data\n",
    "#Here We Are taking first 1,50,000 Sentence-pairs for getting less train complexity\n",
    "\n",
    "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "en_tokenizer.fit_on_texts(english[:150000])\n",
    "data_en = en_tokenizer.texts_to_sequences(english[:150000])\n",
    "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en,\n",
    "                                                        padding='post')\n",
    "print('English sequences')\n",
    "print(data_en[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hRO2XYrQacTd",
    "outputId": "25a384e0-4810-4124-e46a-eff9872d5e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French input sequences\n",
      "[[   2 3059   62    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   2 4163   62    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "#Tokenization On Decoder's Input Data\n",
    "# For Teacher Forcing\n",
    "\n",
    "ita_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "ita_tokenizer.fit_on_texts(italian[:150000])\n",
    "ita_tokenizer.fit_on_texts(output[:150000])\n",
    "data_ita_in = ita_tokenizer.texts_to_sequences(italian[:150000])\n",
    "data_ita_in = tf.keras.preprocessing.sequence.pad_sequences(data_ita_in,\n",
    "                                                           padding='post')\n",
    "print('French input sequences')\n",
    "print(data_ita_in[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kQcjpax-bIe9",
    "outputId": "4ba5d827-e5fd-4a21-c9e6-7d1006bda26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French output sequences\n",
      "[[3059   62    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [4163   62    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "#Tokenization On Decoder's Target Data\n",
    "\n",
    "data_ita_out = ita_tokenizer.texts_to_sequences(output[:150000])\n",
    "data_ita_out = tf.keras.preprocessing.sequence.pad_sequences(data_ita_out,\n",
    "                                                            padding='post')\n",
    "print('French output sequences')\n",
    "print(data_ita_out[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpDcr9FgbjOf"
   },
   "outputs": [],
   "source": [
    "#Preparing Dataset For Customised Training\n",
    "#With BATCH_SIZE = 128\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (data_en, data_ita_in, data_ita_out))\n",
    "dataset = dataset.shuffle(len(english)).batch(\n",
    "    128, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hKvEGLsOb48w",
    "outputId": "33611d16-307a-4583-8a58-67a6980bfbeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 9), (128, 19), (128, 19)), types: (tf.int32, tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJ7Ryu8iSDWv"
   },
   "outputs": [],
   "source": [
    "#Encoder - Class with 1 Layer LSTM\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_size, rnn_size):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.rnn_size = rnn_size\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "    self.lstm = tf.keras.layers.LSTM(rnn_size, \n",
    "                                     return_sequences=True, \n",
    "                                     return_state=True)\n",
    "\n",
    "  def call(self, sequence, states):\n",
    "    embed = self.embedding(sequence)\n",
    "    output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "    return output, state_h, state_c\n",
    "\n",
    "  def init_states(self, batch_size):\n",
    "    return (tf.zeros([batch_size, self.rnn_size]),\n",
    "                tf.zeros([batch_size, self.rnn_size]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#One-Step-Decoder With Luong-Style Attention\n",
    "class OneStepDecoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_size, rnn_size, Score):\n",
    "    super(OneStepDecoder, self).__init__()\n",
    "    self.attention_func = attention_func\n",
    "    self.rnn_size = rnn_size\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "    self.lstm = tf.keras.layers.LSTM(rnn_size,\n",
    "                                     return_sequences=True,\n",
    "                                     return_state=True)\n",
    "    self.wc = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "    self.ws = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    if Score == 'general':\n",
    "      # General score function\n",
    "      self.wa = tf.keras.layers.Dense(rnn_size)\n",
    "    elif Score == 'concat':\n",
    "      # Concat score function\n",
    "      self.wa = tf.keras.layers.Dense(rnn_size, activation='tanh')\n",
    "      self.va = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, decoder_input, encoder_output , state_h,state_c):\n",
    "\n",
    "    # (1)Embedding\n",
    "    embed = self.embedding(decoder_input)\n",
    "\n",
    "    # (2)Passing Embedding Vector in LSTM Cell\n",
    "    #shape (batch_size, 1, rnn_size)\n",
    "    decoder_output, state_h, state_c = self.lstm(embed, initial_state=[state_h, state_c])\n",
    "      \n",
    "    if self.attention_func == 'dot':\n",
    "      \n",
    "      # (3) Calculating Dot Score \n",
    "      score = tf.matmul(decoder_output, encoder_output, transpose_b=True)\n",
    "    \n",
    "    elif self.attention_func == 'general':\n",
    "      \n",
    "      # (3) Calculating General Score \n",
    "      score = tf.matmul(decoder_output, self.wa(encoder_output), \n",
    "                        transpose_b=True)\n",
    "    \n",
    "    elif self.attention_func == 'concat':\n",
    "      #broadcasting Decoder_output for Concating it with encoder output\n",
    "      dec_output = tf.tile(decoder_output, [1, encoder_output.shape[1], 1])\n",
    "            \n",
    "      # (3) Calculating Concat Score \n",
    "      score = self.va(tf.nn.tanh(self.wa(tf.concat((dec_output, encoder_output), axis=-1))))\n",
    "      #(batch_size, 1, max_len)\n",
    "      score = tf.transpose(score, [0, 2, 1])\n",
    "          \n",
    "    # (4)Applying Softmax Layer on  Score\n",
    "    alignment = tf.nn.softmax(score, axis=2)\n",
    "      \n",
    "    # (5)Calculating Context Vector\n",
    "    context = tf.matmul(alignment, encoder_output)\n",
    "      \n",
    "    # (6)Concate Lstm Output and Context Vector  \n",
    "    lstm_out = tf.concat([tf.squeeze(context, 1), tf.squeeze(decoder_output, 1)], 1)\n",
    "\n",
    "    # (7) passing the Results of step- 6 to Dense Layers for getting prediction\n",
    "    lstm_out = self.wc(lstm_out)\n",
    "    logits = self.ws(lstm_out)\n",
    "\n",
    "    return logits, alignment,state_h,state_c\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_size, rnn_size, attention_func):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.attention = OneStepDecoder(vocab_size, embedding_size,rnn_size, attention_func)\n",
    "        \n",
    "  def call(self, sequence, state_h, state_c, encoder_outputs):\n",
    "    outputs = tf.TensorArray(tf.float32, size=sequence.shape[1])\n",
    "        \n",
    "    #Passing Decoder's Input to the One-Step-Attention layer One by One for each Time stamp\n",
    "    for timestamp in range(sequence.shape[1]):\n",
    "      output, alignments, state_h, state_c = self.attention(sequence[:, timestamp:timestamp+1], \n",
    "                                                                 encoder_outputs, \n",
    "                                                                 state_h, \n",
    "                                                                 state_c)\n",
    "        \n",
    "      #Saving the results of timestamp t \n",
    "      outputs = outputs.write(timestamp, output)\n",
    "      \n",
    "    outputs = tf.transpose(outputs.stack(), [1,0,2])\n",
    "    return outputs, state_h, state_c, alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lyIn9NZHQaih"
   },
   "source": [
    "**Model-1 -Dot_Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FK3oErfOQe4e"
   },
   "outputs": [],
   "source": [
    "\"Dot-Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xpXv2UEeVto"
   },
   "outputs": [],
   "source": [
    "#Combining the Both Encoder and Decoder Model for trainig\n",
    "\n",
    "encoder = Encoder(len(en_tokenizer.word_index)+1, 300, 256)\n",
    "decoder = Decoder(len(ita_tokenizer.word_index)+1, 300, 256, 'dot')\n",
    "en_initial_states = encoder.init_states(128)\n",
    "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYUqrh5WTMjG"
   },
   "outputs": [],
   "source": [
    "#Loss Function for Training\n",
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "def loss_func(targets, logits):\n",
    "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HANcd9prTXIo"
   },
   "outputs": [],
   "source": [
    "#Train_step Function for Applying BackPropogation for Custom Trainig\n",
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "\n",
    "@tf.function\n",
    "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(source_seq, en_initial_states)\n",
    "        \n",
    "        #taking State-h and State-c for Decoder \n",
    "        en_states = en_outputs[1:]\n",
    "        de_state_h, de_state_c = en_states\n",
    "\n",
    "        # We need to create a loop to iterate through the target sequences\n",
    "        for i in range(target_seq_out.shape[1]):\n",
    "            \n",
    "            # Input to the decoder must have shape of (batch_size, length)\n",
    "            # so we need to expand one dimension\n",
    "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
    "            logit, de_state_h, de_state_c, _ = decoder(\n",
    "                decoder_in, de_state_h, de_state_c, en_outputs[0])\n",
    "\n",
    "            # The loss is now accumulated through the whole batch\n",
    "            loss += loss_func(target_seq_out[:, i], logit)\n",
    "\n",
    "    #Gradient Update\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss / target_seq_out.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BN6CGUBLTd0I",
    "outputId": "c486a34e-3490-4063-ea4f-c5009ec5e88f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.0832\n",
      "Epoch 1 Batch 100 Loss 1.7826\n",
      "Epoch 1 Batch 200 Loss 1.7955\n",
      "Epoch 1 Batch 300 Loss 1.6871\n",
      "Epoch 1 Batch 400 Loss 1.6926\n",
      "Epoch 1 Batch 500 Loss 1.5650\n",
      "Epoch 1 Batch 600 Loss 1.4592\n",
      "Epoch 1 Batch 700 Loss 1.3822\n",
      "Epoch 1 Batch 800 Loss 1.3030\n",
      "Epoch 1 Batch 900 Loss 1.2946\n",
      "Epoch 1 Batch 1000 Loss 1.2006\n",
      "Epoch 1 Batch 1100 Loss 1.2797\n",
      "Time taken for 1 epoch 314.58012866973877 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.2740\n",
      "Epoch 2 Batch 100 Loss 1.2256\n",
      "Epoch 2 Batch 200 Loss 1.1262\n",
      "Epoch 2 Batch 300 Loss 1.1132\n",
      "Epoch 2 Batch 400 Loss 1.0592\n",
      "Epoch 2 Batch 500 Loss 0.9965\n",
      "Epoch 2 Batch 600 Loss 0.9673\n",
      "Epoch 2 Batch 700 Loss 0.9318\n",
      "Epoch 2 Batch 800 Loss 0.9142\n",
      "Epoch 2 Batch 900 Loss 0.9534\n",
      "Epoch 2 Batch 1000 Loss 0.7957\n",
      "Epoch 2 Batch 1100 Loss 0.8258\n",
      "Time taken for 1 epoch 280.83072328567505 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6952\n",
      "Epoch 3 Batch 100 Loss 0.7276\n",
      "Epoch 3 Batch 200 Loss 0.6573\n",
      "Epoch 3 Batch 300 Loss 0.6498\n",
      "Epoch 3 Batch 400 Loss 0.6019\n",
      "Epoch 3 Batch 500 Loss 0.6069\n",
      "Epoch 3 Batch 600 Loss 0.5807\n",
      "Epoch 3 Batch 700 Loss 0.5186\n",
      "Epoch 3 Batch 800 Loss 0.4767\n",
      "Epoch 3 Batch 900 Loss 0.4879\n",
      "Epoch 3 Batch 1000 Loss 0.4767\n",
      "Epoch 3 Batch 1100 Loss 0.4444\n",
      "Time taken for 1 epoch 280.69713973999023 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.3983\n",
      "Epoch 4 Batch 100 Loss 0.3898\n",
      "Epoch 4 Batch 200 Loss 0.3607\n",
      "Epoch 4 Batch 300 Loss 0.3632\n",
      "Epoch 4 Batch 400 Loss 0.3287\n",
      "Epoch 4 Batch 500 Loss 0.3402\n",
      "Epoch 4 Batch 600 Loss 0.2779\n",
      "Epoch 4 Batch 700 Loss 0.3249\n",
      "Epoch 4 Batch 800 Loss 0.2897\n",
      "Epoch 4 Batch 900 Loss 0.3106\n",
      "Epoch 4 Batch 1000 Loss 0.2933\n",
      "Epoch 4 Batch 1100 Loss 0.2609\n",
      "Time taken for 1 epoch 280.3411936759949 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2083\n",
      "Epoch 5 Batch 100 Loss 0.2389\n",
      "Epoch 5 Batch 200 Loss 0.2104\n",
      "Epoch 5 Batch 300 Loss 0.2341\n",
      "Epoch 5 Batch 400 Loss 0.2230\n",
      "Epoch 5 Batch 500 Loss 0.2110\n",
      "Epoch 5 Batch 600 Loss 0.2257\n",
      "Epoch 5 Batch 700 Loss 0.2181\n",
      "Epoch 5 Batch 800 Loss 0.2087\n",
      "Epoch 5 Batch 900 Loss 0.2349\n",
      "Epoch 5 Batch 1000 Loss 0.2230\n",
      "Epoch 5 Batch 1100 Loss 0.1928\n",
      "Time taken for 1 epoch 280.68203258514404 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1688\n",
      "Epoch 6 Batch 100 Loss 0.1824\n",
      "Epoch 6 Batch 200 Loss 0.1650\n",
      "Epoch 6 Batch 300 Loss 0.1699\n",
      "Epoch 6 Batch 400 Loss 0.1825\n",
      "Epoch 6 Batch 500 Loss 0.1796\n",
      "Epoch 6 Batch 600 Loss 0.2013\n",
      "Epoch 6 Batch 700 Loss 0.1685\n",
      "Epoch 6 Batch 800 Loss 0.1661\n",
      "Epoch 6 Batch 900 Loss 0.1815\n",
      "Epoch 6 Batch 1000 Loss 0.1589\n",
      "Epoch 6 Batch 1100 Loss 0.1790\n",
      "Time taken for 1 epoch 279.94858264923096 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1344\n",
      "Epoch 7 Batch 100 Loss 0.1534\n",
      "Epoch 7 Batch 200 Loss 0.1413\n",
      "Epoch 7 Batch 300 Loss 0.1763\n",
      "Epoch 7 Batch 400 Loss 0.1541\n",
      "Epoch 7 Batch 500 Loss 0.1180\n",
      "Epoch 7 Batch 600 Loss 0.1352\n",
      "Epoch 7 Batch 700 Loss 0.1480\n",
      "Epoch 7 Batch 800 Loss 0.1563\n",
      "Epoch 7 Batch 900 Loss 0.1718\n",
      "Epoch 7 Batch 1000 Loss 0.1609\n",
      "Epoch 7 Batch 1100 Loss 0.1609\n",
      "Time taken for 1 epoch 280.366375207901 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1394\n",
      "Epoch 8 Batch 100 Loss 0.1195\n",
      "Epoch 8 Batch 200 Loss 0.1311\n",
      "Epoch 8 Batch 300 Loss 0.1380\n",
      "Epoch 8 Batch 400 Loss 0.1326\n",
      "Epoch 8 Batch 500 Loss 0.1616\n",
      "Epoch 8 Batch 600 Loss 0.1429\n",
      "Epoch 8 Batch 700 Loss 0.1523\n",
      "Epoch 8 Batch 800 Loss 0.1308\n",
      "Epoch 8 Batch 900 Loss 0.1408\n",
      "Epoch 8 Batch 1000 Loss 0.1262\n",
      "Epoch 8 Batch 1100 Loss 0.1468\n",
      "Time taken for 1 epoch 280.1563642024994 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1170\n",
      "Epoch 9 Batch 100 Loss 0.1007\n",
      "Epoch 9 Batch 200 Loss 0.1144\n",
      "Epoch 9 Batch 300 Loss 0.1264\n",
      "Epoch 9 Batch 400 Loss 0.1234\n",
      "Epoch 9 Batch 500 Loss 0.1089\n",
      "Epoch 9 Batch 600 Loss 0.1437\n",
      "Epoch 9 Batch 700 Loss 0.1370\n",
      "Epoch 9 Batch 800 Loss 0.1387\n",
      "Epoch 9 Batch 900 Loss 0.1275\n",
      "Epoch 9 Batch 1000 Loss 0.1284\n",
      "Epoch 9 Batch 1100 Loss 0.1465\n",
      "Time taken for 1 epoch 279.87918877601624 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1137\n",
      "Epoch 10 Batch 100 Loss 0.1101\n",
      "Epoch 10 Batch 200 Loss 0.1148\n",
      "Epoch 10 Batch 300 Loss 0.1094\n",
      "Epoch 10 Batch 400 Loss 0.1244\n",
      "Epoch 10 Batch 500 Loss 0.1214\n",
      "Epoch 10 Batch 600 Loss 0.1203\n",
      "Epoch 10 Batch 700 Loss 0.1296\n",
      "Epoch 10 Batch 800 Loss 0.1214\n",
      "Epoch 10 Batch 900 Loss 0.1329\n",
      "Epoch 10 Batch 1000 Loss 0.1197\n",
      "Epoch 10 Batch 1100 Loss 0.1320\n",
      "Time taken for 1 epoch 279.430771112442 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0965\n",
      "Epoch 11 Batch 100 Loss 0.1061\n",
      "Epoch 11 Batch 200 Loss 0.1046\n",
      "Epoch 11 Batch 300 Loss 0.1106\n",
      "Epoch 11 Batch 400 Loss 0.1038\n",
      "Epoch 11 Batch 500 Loss 0.1300\n",
      "Epoch 11 Batch 600 Loss 0.1249\n",
      "Epoch 11 Batch 700 Loss 0.1236\n",
      "Epoch 11 Batch 800 Loss 0.1213\n",
      "Epoch 11 Batch 900 Loss 0.1219\n",
      "Epoch 11 Batch 1000 Loss 0.1195\n",
      "Epoch 11 Batch 1100 Loss 0.1471\n",
      "Time taken for 1 epoch 279.5825209617615 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0997\n",
      "Epoch 12 Batch 100 Loss 0.1012\n",
      "Epoch 12 Batch 200 Loss 0.0912\n",
      "Epoch 12 Batch 300 Loss 0.1103\n",
      "Epoch 12 Batch 400 Loss 0.1136\n",
      "Epoch 12 Batch 500 Loss 0.1042\n",
      "Epoch 12 Batch 600 Loss 0.1155\n",
      "Epoch 12 Batch 700 Loss 0.1170\n",
      "Epoch 12 Batch 800 Loss 0.1116\n",
      "Epoch 12 Batch 900 Loss 0.1141\n",
      "Epoch 12 Batch 1000 Loss 0.1252\n",
      "Epoch 12 Batch 1100 Loss 0.1228\n",
      "Time taken for 1 epoch 280.092631816864 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1024\n",
      "Epoch 13 Batch 100 Loss 0.1010\n",
      "Epoch 13 Batch 200 Loss 0.0975\n",
      "Epoch 13 Batch 300 Loss 0.1153\n",
      "Epoch 13 Batch 400 Loss 0.0990\n",
      "Epoch 13 Batch 500 Loss 0.1081\n",
      "Epoch 13 Batch 600 Loss 0.1107\n",
      "Epoch 13 Batch 700 Loss 0.1336\n",
      "Epoch 13 Batch 800 Loss 0.1224\n",
      "Epoch 13 Batch 900 Loss 0.1044\n",
      "Epoch 13 Batch 1000 Loss 0.1131\n",
      "Epoch 13 Batch 1100 Loss 0.1142\n",
      "Time taken for 1 epoch 280.22579407691956 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1057\n",
      "Epoch 14 Batch 100 Loss 0.0941\n",
      "Epoch 14 Batch 200 Loss 0.0967\n",
      "Epoch 14 Batch 300 Loss 0.0958\n",
      "Epoch 14 Batch 400 Loss 0.1024\n",
      "Epoch 14 Batch 500 Loss 0.1109\n",
      "Epoch 14 Batch 600 Loss 0.1098\n",
      "Epoch 14 Batch 700 Loss 0.1157\n",
      "Epoch 14 Batch 800 Loss 0.1092\n",
      "Epoch 14 Batch 900 Loss 0.1017\n",
      "Epoch 14 Batch 1000 Loss 0.1201\n",
      "Epoch 14 Batch 1100 Loss 0.1146\n",
      "Time taken for 1 epoch 279.89427042007446 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0809\n",
      "Epoch 15 Batch 100 Loss 0.1054\n",
      "Epoch 15 Batch 200 Loss 0.1029\n",
      "Epoch 15 Batch 300 Loss 0.1016\n",
      "Epoch 15 Batch 400 Loss 0.1092\n",
      "Epoch 15 Batch 500 Loss 0.1111\n",
      "Epoch 15 Batch 600 Loss 0.1109\n",
      "Epoch 15 Batch 700 Loss 0.1101\n",
      "Epoch 15 Batch 800 Loss 0.1093\n",
      "Epoch 15 Batch 900 Loss 0.1091\n",
      "Epoch 15 Batch 1000 Loss 0.1091\n",
      "Epoch 15 Batch 1100 Loss 0.1153\n",
      "Time taken for 1 epoch 279.6277480125427 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0964\n",
      "Epoch 16 Batch 100 Loss 0.0978\n",
      "Epoch 16 Batch 200 Loss 0.0870\n",
      "Epoch 16 Batch 300 Loss 0.1072\n",
      "Epoch 16 Batch 400 Loss 0.0979\n",
      "Epoch 16 Batch 500 Loss 0.1080\n",
      "Epoch 16 Batch 600 Loss 0.1163\n",
      "Epoch 16 Batch 700 Loss 0.1134\n",
      "Epoch 16 Batch 800 Loss 0.1047\n",
      "Epoch 16 Batch 900 Loss 0.1051\n",
      "Epoch 16 Batch 1000 Loss 0.1167\n",
      "Epoch 16 Batch 1100 Loss 0.1030\n",
      "Time taken for 1 epoch 279.4699673652649 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0967\n",
      "Epoch 17 Batch 100 Loss 0.0926\n",
      "Epoch 17 Batch 200 Loss 0.0948\n",
      "Epoch 17 Batch 300 Loss 0.0898\n",
      "Epoch 17 Batch 400 Loss 0.1051\n",
      "Epoch 17 Batch 500 Loss 0.0921\n",
      "Epoch 17 Batch 600 Loss 0.1097\n",
      "Epoch 17 Batch 700 Loss 0.1017\n",
      "Epoch 17 Batch 800 Loss 0.0985\n",
      "Epoch 17 Batch 900 Loss 0.1057\n",
      "Epoch 17 Batch 1000 Loss 0.1054\n",
      "Epoch 17 Batch 1100 Loss 0.1086\n",
      "Time taken for 1 epoch 279.17215156555176 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0947\n",
      "Epoch 18 Batch 100 Loss 0.0950\n",
      "Epoch 18 Batch 200 Loss 0.0993\n",
      "Epoch 18 Batch 300 Loss 0.0880\n",
      "Epoch 18 Batch 400 Loss 0.1018\n",
      "Epoch 18 Batch 500 Loss 0.0941\n",
      "Epoch 18 Batch 600 Loss 0.1030\n",
      "Epoch 18 Batch 700 Loss 0.1039\n",
      "Epoch 18 Batch 800 Loss 0.1007\n",
      "Epoch 18 Batch 900 Loss 0.1126\n",
      "Epoch 18 Batch 1000 Loss 0.1010\n",
      "Epoch 18 Batch 1100 Loss 0.1085\n",
      "Time taken for 1 epoch 279.26059317588806 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0966\n",
      "Epoch 19 Batch 100 Loss 0.0938\n",
      "Epoch 19 Batch 200 Loss 0.1010\n",
      "Epoch 19 Batch 300 Loss 0.0887\n",
      "Epoch 19 Batch 400 Loss 0.0917\n",
      "Epoch 19 Batch 500 Loss 0.1060\n",
      "Epoch 19 Batch 600 Loss 0.1024\n",
      "Epoch 19 Batch 700 Loss 0.1035\n",
      "Epoch 19 Batch 800 Loss 0.1148\n",
      "Epoch 19 Batch 900 Loss 0.1034\n",
      "Epoch 19 Batch 1000 Loss 0.1041\n",
      "Epoch 19 Batch 1100 Loss 0.1101\n",
      "Time taken for 1 epoch 279.5574884414673 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0938\n",
      "Epoch 20 Batch 100 Loss 0.0780\n",
      "Epoch 20 Batch 200 Loss 0.0824\n",
      "Epoch 20 Batch 300 Loss 0.0964\n",
      "Epoch 20 Batch 400 Loss 0.0912\n",
      "Epoch 20 Batch 500 Loss 0.1029\n",
      "Epoch 20 Batch 600 Loss 0.1116\n",
      "Epoch 20 Batch 700 Loss 0.1000\n",
      "Epoch 20 Batch 800 Loss 0.1019\n",
      "Epoch 20 Batch 900 Loss 0.1080\n",
      "Epoch 20 Batch 1000 Loss 0.1102\n",
      "Epoch 20 Batch 1100 Loss 0.1007\n",
      "Time taken for 1 epoch 279.51802349090576 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0867\n",
      "Epoch 21 Batch 100 Loss 0.1033\n",
      "Epoch 21 Batch 200 Loss 0.0913\n",
      "Epoch 21 Batch 300 Loss 0.0989\n",
      "Epoch 21 Batch 400 Loss 0.0972\n",
      "Epoch 21 Batch 500 Loss 0.0979\n",
      "Epoch 21 Batch 600 Loss 0.0948\n",
      "Epoch 21 Batch 700 Loss 0.0947\n",
      "Epoch 21 Batch 800 Loss 0.0978\n",
      "Epoch 21 Batch 900 Loss 0.1101\n",
      "Epoch 21 Batch 1000 Loss 0.1068\n",
      "Epoch 21 Batch 1100 Loss 0.1044\n",
      "Time taken for 1 epoch 279.3723964691162 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0881\n",
      "Epoch 22 Batch 100 Loss 0.0885\n",
      "Epoch 22 Batch 200 Loss 0.0848\n",
      "Epoch 22 Batch 300 Loss 0.1014\n",
      "Epoch 22 Batch 400 Loss 0.0980\n",
      "Epoch 22 Batch 500 Loss 0.0891\n",
      "Epoch 22 Batch 600 Loss 0.0982\n",
      "Epoch 22 Batch 700 Loss 0.1067\n",
      "Epoch 22 Batch 800 Loss 0.1105\n",
      "Epoch 22 Batch 900 Loss 0.1061\n",
      "Epoch 22 Batch 1000 Loss 0.1055\n",
      "Epoch 22 Batch 1100 Loss 0.1090\n",
      "Time taken for 1 epoch 280.3431179523468 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0815\n",
      "Epoch 23 Batch 100 Loss 0.0901\n",
      "Epoch 23 Batch 200 Loss 0.0903\n",
      "Epoch 23 Batch 300 Loss 0.0967\n",
      "Epoch 23 Batch 400 Loss 0.0921\n",
      "Epoch 23 Batch 500 Loss 0.0958\n",
      "Epoch 23 Batch 600 Loss 0.0933\n",
      "Epoch 23 Batch 700 Loss 0.1000\n",
      "Epoch 23 Batch 800 Loss 0.1046\n",
      "Epoch 23 Batch 900 Loss 0.1095\n",
      "Epoch 23 Batch 1000 Loss 0.1018\n",
      "Epoch 23 Batch 1100 Loss 0.0969\n",
      "Time taken for 1 epoch 280.5663232803345 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0804\n",
      "Epoch 24 Batch 100 Loss 0.0988\n",
      "Epoch 24 Batch 200 Loss 0.0818\n",
      "Epoch 24 Batch 300 Loss 0.1026\n",
      "Epoch 24 Batch 400 Loss 0.0943\n",
      "Epoch 24 Batch 500 Loss 0.0956\n",
      "Epoch 24 Batch 600 Loss 0.0963\n",
      "Epoch 24 Batch 700 Loss 0.1009\n",
      "Epoch 24 Batch 800 Loss 0.0975\n",
      "Epoch 24 Batch 900 Loss 0.1047\n",
      "Epoch 24 Batch 1000 Loss 0.1061\n",
      "Epoch 24 Batch 1100 Loss 0.1033\n",
      "Time taken for 1 epoch 281.5052897930145 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0979\n",
      "Epoch 25 Batch 100 Loss 0.0823\n",
      "Epoch 25 Batch 200 Loss 0.0879\n",
      "Epoch 25 Batch 300 Loss 0.0889\n",
      "Epoch 25 Batch 400 Loss 0.0999\n",
      "Epoch 25 Batch 500 Loss 0.1007\n",
      "Epoch 25 Batch 600 Loss 0.0883\n",
      "Epoch 25 Batch 700 Loss 0.1000\n",
      "Epoch 25 Batch 800 Loss 0.1121\n",
      "Epoch 25 Batch 900 Loss 0.1016\n",
      "Epoch 25 Batch 1000 Loss 0.1077\n",
      "Epoch 25 Batch 1100 Loss 0.1020\n",
      "Time taken for 1 epoch 282.1590311527252 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training Process\n",
    "\n",
    "import time\n",
    "for e in range(25):\n",
    "  start = time.time()\n",
    "  \n",
    "  #Saving Weights\n",
    "  encoder.save_weights(\n",
    "            '/content/drive/My Drive/Attention Models/saved_model/Check/Encoder/encoder_{}.h5'.format(e + 1))\n",
    "  decoder.save_weights(\n",
    "            '/content/drive/My Drive/Attention Models/saved_model/Check/Decoder/decoder_{}.h5'.format(e + 1))\n",
    "  for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "    loss = train_step(source_seq, target_seq_in,\n",
    "                              target_seq_out, en_initial_states)\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(e + 1, batch, loss.numpy()))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOkEBnL4czoZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#Predicting(Translating) Sentence\n",
    "def predict(i):\n",
    "  en_out, state_h, state_c = encoder(data_en[i:i+1],encoder.init_states(1))\n",
    "  eng = [en_tokenizer.index_word[idx] for idx in data_en[i:i+1][0] if idx !=0]\n",
    "  ita = [ita_tokenizer.index_word[idx] for idx in data_ita_in[i:i+1][0] \n",
    "                                    if idx !=0 \n",
    "                                        and ita_tokenizer.index_word[idx]!='<start>']\n",
    "  vec = np.array(ita_tokenizer.word_index['<start>']).reshape(1,1)\n",
    "  out = []\n",
    "  weights = []\n",
    "  while(50):  \n",
    "    de_out, state_h,state_c, w = decoder(vec, state_h, state_c, en_out)\n",
    "    vec = np.argmax(de_out[0][0]).reshape(1,1)\n",
    "    if ita_tokenizer.index_word[np.argmax(de_out[0][0])] == '<end>':\n",
    "      break\n",
    "    out.append(ita_tokenizer.index_word[np.argmax(de_out[0][0])])\n",
    "    weights.append(list(w[0][0].numpy()))\n",
    "\n",
    "  print(\"English:             \",' '.join(eng))\n",
    "  print(\"Translated(italian): \",' '.join(out))\n",
    "\n",
    "  plot_attention(np.array(weights), eng, out)\n",
    "  return ita, out\n",
    "\n",
    "\n",
    "\n",
    "# function for plotting the attention weights\n",
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention[:,0:len(sentence)], cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "q-hGhfm9OCIj",
    "outputId": "c4767f8a-f8ca-49a6-e62b-ca897716a01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:              correct me if i'm wrong .\n",
      "Translated(italian):  mi corregga se sbaglio .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita , out = predict(126700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "A1QFlqTIZ6Zp",
    "outputId": "6c2c2db8-b9cd-43ab-aa41-dfc2b4813b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:              my new job starts monday .\n",
      "Translated(italian):  il mio nuovo lavoro comincia lunedi .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita, out = predict(149000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kTVPcUBVatC3",
    "outputId": "2868bd86-43d7-4389-89bc-820cd1320b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu-score:  0.6147881529512643\n"
     ]
    }
   ],
   "source": [
    "#Bleu-Score for Dot-Score Model\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "score = sentence_bleu(ita, out)\n",
    "print(\"Bleu-score: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bs0WejV1Qsbt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjYoDZBNQtZt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRXcN0p5Ib9_"
   },
   "source": [
    "**Model - 2 General_Score**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdtR6AUEQuRb"
   },
   "outputs": [],
   "source": [
    "\"General Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsmckWOjazjv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K \n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZdZXbBBxazrR",
    "outputId": "74e2ae35-5b67-41bb-cabf-c9a1cfb1076f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.1153\n",
      "Epoch 1 Batch 100 Loss 1.7000\n",
      "Epoch 1 Batch 200 Loss 1.6604\n",
      "Epoch 1 Batch 300 Loss 1.6032\n",
      "Epoch 1 Batch 400 Loss 1.5006\n",
      "Epoch 1 Batch 500 Loss 1.4569\n",
      "Epoch 1 Batch 600 Loss 1.4743\n",
      "Epoch 1 Batch 700 Loss 1.4231\n",
      "Epoch 1 Batch 800 Loss 1.3644\n",
      "Epoch 1 Batch 900 Loss 1.2159\n",
      "Epoch 1 Batch 1000 Loss 1.2528\n",
      "Epoch 1 Batch 1100 Loss 1.0949\n",
      "Time taken for 1 epoch 333.62171721458435 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.0122\n",
      "Epoch 2 Batch 100 Loss 0.9777\n",
      "Epoch 2 Batch 200 Loss 0.9443\n",
      "Epoch 2 Batch 300 Loss 0.8626\n",
      "Epoch 2 Batch 400 Loss 0.7949\n",
      "Epoch 2 Batch 500 Loss 0.7643\n",
      "Epoch 2 Batch 600 Loss 0.7268\n",
      "Epoch 2 Batch 700 Loss 0.7420\n",
      "Epoch 2 Batch 800 Loss 0.6249\n",
      "Epoch 2 Batch 900 Loss 0.6365\n",
      "Epoch 2 Batch 1000 Loss 0.6324\n",
      "Epoch 2 Batch 1100 Loss 0.5704\n",
      "Time taken for 1 epoch 301.40501737594604 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.5002\n",
      "Epoch 3 Batch 100 Loss 0.4870\n",
      "Epoch 3 Batch 200 Loss 0.4944\n",
      "Epoch 3 Batch 300 Loss 0.5002\n",
      "Epoch 3 Batch 400 Loss 0.4905\n",
      "Epoch 3 Batch 500 Loss 0.4198\n",
      "Epoch 3 Batch 600 Loss 0.4436\n",
      "Epoch 3 Batch 700 Loss 0.4333\n",
      "Epoch 3 Batch 800 Loss 0.4111\n",
      "Epoch 3 Batch 900 Loss 0.3678\n",
      "Epoch 3 Batch 1000 Loss 0.3557\n",
      "Epoch 3 Batch 1100 Loss 0.3851\n",
      "Time taken for 1 epoch 301.15777945518494 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2891\n",
      "Epoch 4 Batch 100 Loss 0.3337\n",
      "Epoch 4 Batch 200 Loss 0.3224\n",
      "Epoch 4 Batch 300 Loss 0.2842\n",
      "Epoch 4 Batch 400 Loss 0.3253\n",
      "Epoch 4 Batch 500 Loss 0.3119\n",
      "Epoch 4 Batch 600 Loss 0.2905\n",
      "Epoch 4 Batch 700 Loss 0.2992\n",
      "Epoch 4 Batch 800 Loss 0.2981\n",
      "Epoch 4 Batch 900 Loss 0.3171\n",
      "Epoch 4 Batch 1000 Loss 0.2909\n",
      "Epoch 4 Batch 1100 Loss 0.2654\n",
      "Time taken for 1 epoch 300.9162275791168 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2301\n",
      "Epoch 5 Batch 100 Loss 0.2324\n",
      "Epoch 5 Batch 200 Loss 0.2316\n",
      "Epoch 5 Batch 300 Loss 0.2490\n",
      "Epoch 5 Batch 400 Loss 0.2210\n",
      "Epoch 5 Batch 500 Loss 0.2298\n",
      "Epoch 5 Batch 600 Loss 0.2611\n",
      "Epoch 5 Batch 700 Loss 0.2231\n",
      "Epoch 5 Batch 800 Loss 0.2261\n",
      "Epoch 5 Batch 900 Loss 0.2322\n",
      "Epoch 5 Batch 1000 Loss 0.2230\n",
      "Epoch 5 Batch 1100 Loss 0.2244\n",
      "Time taken for 1 epoch 301.02286887168884 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1902\n",
      "Epoch 6 Batch 100 Loss 0.1937\n",
      "Epoch 6 Batch 200 Loss 0.1565\n",
      "Epoch 6 Batch 300 Loss 0.1770\n",
      "Epoch 6 Batch 400 Loss 0.1794\n",
      "Epoch 6 Batch 500 Loss 0.1815\n",
      "Epoch 6 Batch 600 Loss 0.1937\n",
      "Epoch 6 Batch 700 Loss 0.2106\n",
      "Epoch 6 Batch 800 Loss 0.1904\n",
      "Epoch 6 Batch 900 Loss 0.1857\n",
      "Epoch 6 Batch 1000 Loss 0.1937\n",
      "Epoch 6 Batch 1100 Loss 0.1757\n",
      "Time taken for 1 epoch 301.2919340133667 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1641\n",
      "Epoch 7 Batch 100 Loss 0.1515\n",
      "Epoch 7 Batch 200 Loss 0.1376\n",
      "Epoch 7 Batch 300 Loss 0.1873\n",
      "Epoch 7 Batch 400 Loss 0.1658\n",
      "Epoch 7 Batch 500 Loss 0.1763\n",
      "Epoch 7 Batch 600 Loss 0.1677\n",
      "Epoch 7 Batch 700 Loss 0.1660\n",
      "Epoch 7 Batch 800 Loss 0.1748\n",
      "Epoch 7 Batch 900 Loss 0.1437\n",
      "Epoch 7 Batch 1000 Loss 0.1719\n",
      "Epoch 7 Batch 1100 Loss 0.1708\n",
      "Time taken for 1 epoch 300.89570474624634 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1313\n",
      "Epoch 8 Batch 100 Loss 0.1328\n",
      "Epoch 8 Batch 200 Loss 0.1521\n",
      "Epoch 8 Batch 300 Loss 0.1576\n",
      "Epoch 8 Batch 400 Loss 0.1574\n",
      "Epoch 8 Batch 500 Loss 0.1317\n",
      "Epoch 8 Batch 600 Loss 0.1649\n",
      "Epoch 8 Batch 700 Loss 0.1515\n",
      "Epoch 8 Batch 800 Loss 0.1510\n",
      "Epoch 8 Batch 900 Loss 0.1909\n",
      "Epoch 8 Batch 1000 Loss 0.1434\n",
      "Epoch 8 Batch 1100 Loss 0.1613\n",
      "Time taken for 1 epoch 300.6756811141968 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1231\n",
      "Epoch 9 Batch 100 Loss 0.1556\n",
      "Epoch 9 Batch 200 Loss 0.1482\n",
      "Epoch 9 Batch 300 Loss 0.1556\n",
      "Epoch 9 Batch 400 Loss 0.1368\n",
      "Epoch 9 Batch 500 Loss 0.1403\n",
      "Epoch 9 Batch 600 Loss 0.1351\n",
      "Epoch 9 Batch 700 Loss 0.1307\n",
      "Epoch 9 Batch 800 Loss 0.1505\n",
      "Epoch 9 Batch 900 Loss 0.1445\n",
      "Epoch 9 Batch 1000 Loss 0.1423\n",
      "Epoch 9 Batch 1100 Loss 0.1637\n",
      "Time taken for 1 epoch 301.399037361145 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1319\n",
      "Epoch 10 Batch 100 Loss 0.1198\n",
      "Epoch 10 Batch 200 Loss 0.1366\n",
      "Epoch 10 Batch 300 Loss 0.1374\n",
      "Epoch 10 Batch 400 Loss 0.1484\n",
      "Epoch 10 Batch 500 Loss 0.1419\n",
      "Epoch 10 Batch 600 Loss 0.1291\n",
      "Epoch 10 Batch 700 Loss 0.1470\n",
      "Epoch 10 Batch 800 Loss 0.1457\n",
      "Epoch 10 Batch 900 Loss 0.1553\n",
      "Epoch 10 Batch 1000 Loss 0.1444\n",
      "Epoch 10 Batch 1100 Loss 0.1365\n",
      "Time taken for 1 epoch 301.07420086860657 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1083\n",
      "Epoch 11 Batch 100 Loss 0.1244\n",
      "Epoch 11 Batch 200 Loss 0.1237\n",
      "Epoch 11 Batch 300 Loss 0.1406\n",
      "Epoch 11 Batch 400 Loss 0.1201\n",
      "Epoch 11 Batch 500 Loss 0.1272\n",
      "Epoch 11 Batch 600 Loss 0.1282\n",
      "Epoch 11 Batch 700 Loss 0.1287\n",
      "Epoch 11 Batch 800 Loss 0.1297\n",
      "Epoch 11 Batch 900 Loss 0.1573\n",
      "Epoch 11 Batch 1000 Loss 0.1293\n",
      "Epoch 11 Batch 1100 Loss 0.1449\n",
      "Time taken for 1 epoch 300.8755931854248 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1164\n",
      "Epoch 12 Batch 100 Loss 0.1300\n",
      "Epoch 12 Batch 200 Loss 0.1119\n",
      "Epoch 12 Batch 300 Loss 0.1148\n",
      "Epoch 12 Batch 400 Loss 0.1246\n",
      "Epoch 12 Batch 500 Loss 0.1247\n",
      "Epoch 12 Batch 600 Loss 0.1230\n",
      "Epoch 12 Batch 700 Loss 0.1303\n",
      "Epoch 12 Batch 800 Loss 0.1477\n",
      "Epoch 12 Batch 900 Loss 0.1206\n",
      "Epoch 12 Batch 1000 Loss 0.1326\n",
      "Epoch 12 Batch 1100 Loss 0.1322\n",
      "Time taken for 1 epoch 299.8533983230591 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0992\n",
      "Epoch 13 Batch 100 Loss 0.1063\n",
      "Epoch 13 Batch 200 Loss 0.1115\n",
      "Epoch 13 Batch 300 Loss 0.1153\n",
      "Epoch 13 Batch 400 Loss 0.1126\n",
      "Epoch 13 Batch 500 Loss 0.1126\n",
      "Epoch 13 Batch 600 Loss 0.1280\n",
      "Epoch 13 Batch 700 Loss 0.1219\n",
      "Epoch 13 Batch 800 Loss 0.1109\n",
      "Epoch 13 Batch 900 Loss 0.1292\n",
      "Epoch 13 Batch 1000 Loss 0.1163\n",
      "Epoch 13 Batch 1100 Loss 0.1379\n",
      "Time taken for 1 epoch 299.474573135376 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1239\n",
      "Epoch 14 Batch 100 Loss 0.1083\n",
      "Epoch 14 Batch 200 Loss 0.1017\n",
      "Epoch 14 Batch 300 Loss 0.1003\n",
      "Epoch 14 Batch 400 Loss 0.1189\n",
      "Epoch 14 Batch 500 Loss 0.1147\n",
      "Epoch 14 Batch 600 Loss 0.1151\n",
      "Epoch 14 Batch 700 Loss 0.1280\n",
      "Epoch 14 Batch 800 Loss 0.1268\n",
      "Epoch 14 Batch 900 Loss 0.1403\n",
      "Epoch 14 Batch 1000 Loss 0.1035\n",
      "Epoch 14 Batch 1100 Loss 0.1230\n",
      "Time taken for 1 epoch 299.76863074302673 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1088\n",
      "Epoch 15 Batch 100 Loss 0.0910\n",
      "Epoch 15 Batch 200 Loss 0.1085\n",
      "Epoch 15 Batch 300 Loss 0.1026\n",
      "Epoch 15 Batch 400 Loss 0.1037\n",
      "Epoch 15 Batch 500 Loss 0.1099\n",
      "Epoch 15 Batch 600 Loss 0.1238\n",
      "Epoch 15 Batch 700 Loss 0.1100\n",
      "Epoch 15 Batch 800 Loss 0.1097\n",
      "Epoch 15 Batch 900 Loss 0.1283\n",
      "Epoch 15 Batch 1000 Loss 0.1285\n",
      "Epoch 15 Batch 1100 Loss 0.1069\n",
      "Time taken for 1 epoch 299.61136960983276 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0994\n",
      "Epoch 16 Batch 100 Loss 0.0997\n",
      "Epoch 16 Batch 200 Loss 0.1082\n",
      "Epoch 16 Batch 300 Loss 0.1126\n",
      "Epoch 16 Batch 400 Loss 0.1087\n",
      "Epoch 16 Batch 500 Loss 0.1120\n",
      "Epoch 16 Batch 600 Loss 0.1158\n",
      "Epoch 16 Batch 700 Loss 0.1134\n",
      "Epoch 16 Batch 800 Loss 0.1150\n",
      "Epoch 16 Batch 900 Loss 0.1145\n",
      "Epoch 16 Batch 1000 Loss 0.1234\n",
      "Epoch 16 Batch 1100 Loss 0.1101\n",
      "Time taken for 1 epoch 299.81084632873535 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.1082\n",
      "Epoch 17 Batch 100 Loss 0.1017\n",
      "Epoch 17 Batch 200 Loss 0.1025\n",
      "Epoch 17 Batch 300 Loss 0.0931\n",
      "Epoch 17 Batch 400 Loss 0.1138\n",
      "Epoch 17 Batch 500 Loss 0.1074\n",
      "Epoch 17 Batch 600 Loss 0.1115\n",
      "Epoch 17 Batch 700 Loss 0.1061\n",
      "Epoch 17 Batch 800 Loss 0.1102\n",
      "Epoch 17 Batch 900 Loss 0.1103\n",
      "Epoch 17 Batch 1000 Loss 0.1116\n",
      "Epoch 17 Batch 1100 Loss 0.1138\n",
      "Time taken for 1 epoch 299.86337208747864 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0948\n",
      "Epoch 18 Batch 100 Loss 0.1016\n",
      "Epoch 18 Batch 200 Loss 0.1023\n",
      "Epoch 18 Batch 300 Loss 0.1040\n",
      "Epoch 18 Batch 400 Loss 0.1131\n",
      "Epoch 18 Batch 500 Loss 0.1151\n",
      "Epoch 18 Batch 600 Loss 0.1013\n",
      "Epoch 18 Batch 700 Loss 0.1156\n",
      "Epoch 18 Batch 800 Loss 0.1133\n",
      "Epoch 18 Batch 900 Loss 0.1162\n",
      "Epoch 18 Batch 1000 Loss 0.1193\n",
      "Epoch 18 Batch 1100 Loss 0.1085\n",
      "Time taken for 1 epoch 299.4666748046875 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0980\n",
      "Epoch 19 Batch 100 Loss 0.0899\n",
      "Epoch 19 Batch 200 Loss 0.1077\n",
      "Epoch 19 Batch 300 Loss 0.0994\n",
      "Epoch 19 Batch 400 Loss 0.0980\n",
      "Epoch 19 Batch 500 Loss 0.1182\n",
      "Epoch 19 Batch 600 Loss 0.1094\n",
      "Epoch 19 Batch 700 Loss 0.1007\n",
      "Epoch 19 Batch 800 Loss 0.1207\n",
      "Epoch 19 Batch 900 Loss 0.1180\n",
      "Epoch 19 Batch 1000 Loss 0.1233\n",
      "Epoch 19 Batch 1100 Loss 0.1309\n",
      "Time taken for 1 epoch 300.15287351608276 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1012\n",
      "Epoch 20 Batch 100 Loss 0.1009\n",
      "Epoch 20 Batch 200 Loss 0.0886\n",
      "Epoch 20 Batch 300 Loss 0.0917\n",
      "Epoch 20 Batch 400 Loss 0.1067\n",
      "Epoch 20 Batch 500 Loss 0.0982\n",
      "Epoch 20 Batch 600 Loss 0.1086\n",
      "Epoch 20 Batch 700 Loss 0.1078\n",
      "Epoch 20 Batch 800 Loss 0.1045\n",
      "Epoch 20 Batch 900 Loss 0.1180\n",
      "Epoch 20 Batch 1000 Loss 0.1238\n",
      "Epoch 20 Batch 1100 Loss 0.1077\n",
      "Time taken for 1 epoch 299.9913694858551 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0969\n",
      "Epoch 21 Batch 100 Loss 0.0881\n",
      "Epoch 21 Batch 200 Loss 0.0933\n",
      "Epoch 21 Batch 300 Loss 0.0993\n",
      "Epoch 21 Batch 400 Loss 0.0878\n",
      "Epoch 21 Batch 500 Loss 0.0958\n",
      "Epoch 21 Batch 600 Loss 0.1086\n",
      "Epoch 21 Batch 700 Loss 0.1073\n",
      "Epoch 21 Batch 800 Loss 0.1110\n",
      "Epoch 21 Batch 900 Loss 0.1255\n",
      "Epoch 21 Batch 1000 Loss 0.1113\n",
      "Epoch 21 Batch 1100 Loss 0.1158\n",
      "Time taken for 1 epoch 299.99503564834595 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.1022\n",
      "Epoch 22 Batch 100 Loss 0.1060\n",
      "Epoch 22 Batch 200 Loss 0.0992\n",
      "Epoch 22 Batch 300 Loss 0.1030\n",
      "Epoch 22 Batch 400 Loss 0.0834\n",
      "Epoch 22 Batch 500 Loss 0.1130\n",
      "Epoch 22 Batch 600 Loss 0.0941\n",
      "Epoch 22 Batch 700 Loss 0.1028\n",
      "Epoch 22 Batch 800 Loss 0.1085\n",
      "Epoch 22 Batch 900 Loss 0.1088\n",
      "Epoch 22 Batch 1000 Loss 0.1228\n",
      "Epoch 22 Batch 1100 Loss 0.1122\n",
      "Time taken for 1 epoch 300.2225046157837 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0942\n",
      "Epoch 23 Batch 100 Loss 0.0940\n",
      "Epoch 23 Batch 200 Loss 0.1019\n",
      "Epoch 23 Batch 300 Loss 0.0894\n",
      "Epoch 23 Batch 400 Loss 0.0981\n",
      "Epoch 23 Batch 500 Loss 0.0899\n",
      "Epoch 23 Batch 600 Loss 0.1053\n",
      "Epoch 23 Batch 700 Loss 0.0949\n",
      "Epoch 23 Batch 800 Loss 0.1116\n",
      "Epoch 23 Batch 900 Loss 0.0955\n",
      "Epoch 23 Batch 1000 Loss 0.1021\n",
      "Epoch 23 Batch 1100 Loss 0.1097\n",
      "Time taken for 1 epoch 300.1694977283478 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0926\n",
      "Epoch 24 Batch 100 Loss 0.0975\n",
      "Epoch 24 Batch 200 Loss 0.0905\n",
      "Epoch 24 Batch 300 Loss 0.1039\n",
      "Epoch 24 Batch 400 Loss 0.1017\n",
      "Epoch 24 Batch 500 Loss 0.1021\n",
      "Epoch 24 Batch 600 Loss 0.1010\n",
      "Epoch 24 Batch 700 Loss 0.1116\n",
      "Epoch 24 Batch 800 Loss 0.1074\n",
      "Epoch 24 Batch 900 Loss 0.1055\n",
      "Epoch 24 Batch 1000 Loss 0.1166\n",
      "Epoch 24 Batch 1100 Loss 0.1020\n",
      "Time taken for 1 epoch 299.89686346054077 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0853\n",
      "Epoch 25 Batch 100 Loss 0.0837\n",
      "Epoch 25 Batch 200 Loss 0.0934\n",
      "Epoch 25 Batch 300 Loss 0.0989\n",
      "Epoch 25 Batch 400 Loss 0.0979\n",
      "Epoch 25 Batch 500 Loss 0.1079\n",
      "Epoch 25 Batch 600 Loss 0.0954\n",
      "Epoch 25 Batch 700 Loss 0.1084\n",
      "Epoch 25 Batch 800 Loss 0.1094\n",
      "Epoch 25 Batch 900 Loss 0.0957\n",
      "Epoch 25 Batch 1000 Loss 0.1163\n",
      "Epoch 25 Batch 1100 Loss 0.1086\n",
      "Time taken for 1 epoch 299.4397134780884 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize Model \n",
    "\n",
    "encoder2 = Encoder(len(en_tokenizer.word_index)+1, 300, 256)\n",
    "decoder2 = Decoder(len(ita_tokenizer.word_index)+1, 300, 256, 'general')\n",
    "en_initial_states = encoder2.init_states(128)\n",
    "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
    "\n",
    "#training Step\n",
    "@tf.function\n",
    "def train_step2(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder2(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_state_h, de_state_c = en_states\n",
    "\n",
    "        # We need to create a loop to iterate through the target sequences\n",
    "        for i in range(target_seq_out.shape[1]):\n",
    "            # Input to the decoder must have shape of (batch_size, length)\n",
    "            # so we need to expand one dimension\n",
    "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
    "            logit, de_state_h, de_state_c, _ = decoder2(\n",
    "                decoder_in, de_state_h, de_state_c, en_outputs[0])\n",
    "\n",
    "            # The loss is now accumulated through the whole batch\n",
    "            loss += loss_func(target_seq_out[:, i], logit)\n",
    "\n",
    "    #Gradient Update\n",
    "    variables = encoder2.trainable_variables + decoder2.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss / target_seq_out.shape[1]\n",
    "\n",
    "import time\n",
    "for e in range(25):\n",
    "  start = time.time()\n",
    "  #Saving Weights\n",
    "  encoder2.save_weights(\n",
    "            '/content/drive/My Drive/Attention Models/saved_model/Check2/Encoder/encoder_{}.h5'.format(e + 1))\n",
    "  decoder2.save_weights(\n",
    "            '/content/drive/My Drive/Attention Models/saved_model/Check2/Decoder/decoder_{}.h5'.format(e + 1))\n",
    "  for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "    loss = train_step2(source_seq, target_seq_in,\n",
    "                              target_seq_out, en_initial_states)\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(e + 1, batch, loss.numpy()))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVfduQFfrvkt"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Predicting(Translating) Sentence\n",
    "def predict2(i):\n",
    "  en_out, state_h, state_c = encoder2(data_en[i:i+1],encoder.init_states(1))\n",
    "  eng = [en_tokenizer.index_word[idx] for idx in data_en[i:i+1][0] if idx !=0]\n",
    "  ita = [ita_tokenizer.index_word[idx] for idx in data_ita_in[i:i+1][0] \n",
    "                                    if idx !=0 \n",
    "                                        and ita_tokenizer.index_word[idx]!='<start>']\n",
    "  vec = np.array(ita_tokenizer.word_index['<start>']).reshape(1,1)\n",
    "  out = []\n",
    "  weights = []\n",
    "  while(50):  \n",
    "    de_out, state_h,state_c, w = decoder2(vec, state_h, state_c, en_out)\n",
    "    vec = np.argmax(de_out[0][0]).reshape(1,1)\n",
    "    if ita_tokenizer.index_word[np.argmax(de_out[0][0])] == '<end>':\n",
    "      break\n",
    "    out.append(ita_tokenizer.index_word[np.argmax(de_out[0][0])])\n",
    "    weights.append(list(w[0][0].numpy()))\n",
    "\n",
    "  print(\"English:             \",' '.join(eng))\n",
    "  print(\"Translated(italian): \",' '.join(out))\n",
    "\n",
    "  plot_attention(np.array(weights), eng, out)\n",
    "  return ita, out\n",
    "\n",
    "# function for plotting the attention weights\n",
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention[:,0:len(sentence)], cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "oVivkqsgrzpL",
    "outputId": "e3a66bc4-915b-424e-df1d-0e34fb90fb04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:              my new job starts monday .\n",
      "Translated(italian):  il mio nuovo impiego comincia lunedi .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita, out = predict2(148999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "id": "MMWITnlksK-W",
    "outputId": "5d174639-4a94-477d-96e2-df1744d1f71c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:              my robot's name is multi .\n",
      "Translated(italian):  il mio robot si chiama multi .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita, out = predict2(149010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kbe0CoksJQSZ",
    "outputId": "edaa1e12-42b8-4427-e308-01d92aae786a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  il nome del mio robot e multi .\n",
      "Prediction:  il mio robot si chiama multi .\n",
      "Bleu-score (General-Score):  0.6147881529512643\n"
     ]
    }
   ],
   "source": [
    "#Bleu-Score for General-Score Model\n",
    "\n",
    "print(\"Target: \",' '.join(ita))\n",
    "print(\"Prediction: \",' '.join(out))\n",
    "\n",
    "score = sentence_bleu(ita, out)\n",
    "print(\"Bleu-score (General-Score): \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYaz7LGMJQfP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJ2gKmTXRXwN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8PM4IrdFJNHQ"
   },
   "source": [
    "**Model - 3 Concat_Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvFvZiivRVVL"
   },
   "outputs": [],
   "source": [
    "\"Concate_Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cigssWu5s9CX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K \n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kNMYA8V3s9ML",
    "outputId": "4d892b15-95a1-45ca-856e-4bc3aaaa8228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.0512\n",
      "Epoch 1 Batch 100 Loss 1.7350\n",
      "Epoch 1 Batch 200 Loss 1.6528\n",
      "Epoch 1 Batch 300 Loss 1.6437\n",
      "Epoch 1 Batch 400 Loss 1.6548\n",
      "Epoch 1 Batch 500 Loss 1.4654\n",
      "Epoch 1 Batch 600 Loss 1.5036\n",
      "Epoch 1 Batch 700 Loss 1.4238\n",
      "Epoch 1 Batch 800 Loss 1.2735\n",
      "Epoch 1 Batch 900 Loss 1.2592\n",
      "Epoch 1 Batch 1000 Loss 1.1280\n",
      "Epoch 1 Batch 1100 Loss 1.0652\n",
      "Time taken for 1 epoch 363.07117986679077 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.9432\n",
      "Epoch 2 Batch 100 Loss 0.9590\n",
      "Epoch 2 Batch 200 Loss 0.9209\n",
      "Epoch 2 Batch 300 Loss 0.8667\n",
      "Epoch 2 Batch 400 Loss 0.7585\n",
      "Epoch 2 Batch 500 Loss 0.7658\n",
      "Epoch 2 Batch 600 Loss 0.6789\n",
      "Epoch 2 Batch 700 Loss 0.6374\n",
      "Epoch 2 Batch 800 Loss 0.6210\n",
      "Epoch 2 Batch 900 Loss 0.5739\n",
      "Epoch 2 Batch 1000 Loss 0.5448\n",
      "Epoch 2 Batch 1100 Loss 0.5309\n",
      "Time taken for 1 epoch 321.28168773651123 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.4708\n",
      "Epoch 3 Batch 100 Loss 0.4332\n",
      "Epoch 3 Batch 200 Loss 0.4225\n",
      "Epoch 3 Batch 300 Loss 0.3912\n",
      "Epoch 3 Batch 400 Loss 0.3845\n",
      "Epoch 3 Batch 500 Loss 0.3645\n",
      "Epoch 3 Batch 600 Loss 0.3655\n",
      "Epoch 3 Batch 700 Loss 0.3805\n",
      "Epoch 3 Batch 800 Loss 0.3373\n",
      "Epoch 3 Batch 900 Loss 0.3258\n",
      "Epoch 3 Batch 1000 Loss 0.3050\n",
      "Epoch 3 Batch 1100 Loss 0.2788\n",
      "Time taken for 1 epoch 321.10709977149963 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2490\n",
      "Epoch 4 Batch 100 Loss 0.2431\n",
      "Epoch 4 Batch 200 Loss 0.2563\n",
      "Epoch 4 Batch 300 Loss 0.2723\n",
      "Epoch 4 Batch 400 Loss 0.2392\n",
      "Epoch 4 Batch 500 Loss 0.2417\n",
      "Epoch 4 Batch 600 Loss 0.2467\n",
      "Epoch 4 Batch 700 Loss 0.2185\n",
      "Epoch 4 Batch 800 Loss 0.2186\n",
      "Epoch 4 Batch 900 Loss 0.2336\n",
      "Epoch 4 Batch 1000 Loss 0.2397\n",
      "Epoch 4 Batch 1100 Loss 0.2437\n",
      "Time taken for 1 epoch 320.677286863327 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1579\n",
      "Epoch 5 Batch 100 Loss 0.1758\n",
      "Epoch 5 Batch 200 Loss 0.1571\n",
      "Epoch 5 Batch 300 Loss 0.2022\n",
      "Epoch 5 Batch 400 Loss 0.1717\n",
      "Epoch 5 Batch 500 Loss 0.1847\n",
      "Epoch 5 Batch 600 Loss 0.1854\n",
      "Epoch 5 Batch 700 Loss 0.1858\n",
      "Epoch 5 Batch 800 Loss 0.1634\n",
      "Epoch 5 Batch 900 Loss 0.2230\n",
      "Epoch 5 Batch 1000 Loss 0.1942\n",
      "Epoch 5 Batch 1100 Loss 0.1714\n",
      "Time taken for 1 epoch 321.0804660320282 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1338\n",
      "Epoch 6 Batch 100 Loss 0.1508\n",
      "Epoch 6 Batch 200 Loss 0.1705\n",
      "Epoch 6 Batch 300 Loss 0.1521\n",
      "Epoch 6 Batch 400 Loss 0.1409\n",
      "Epoch 6 Batch 500 Loss 0.1300\n",
      "Epoch 6 Batch 600 Loss 0.1609\n",
      "Epoch 6 Batch 700 Loss 0.1509\n",
      "Epoch 6 Batch 800 Loss 0.1542\n",
      "Epoch 6 Batch 900 Loss 0.1668\n",
      "Epoch 6 Batch 1000 Loss 0.1740\n",
      "Epoch 6 Batch 1100 Loss 0.1453\n",
      "Time taken for 1 epoch 321.0652892589569 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1364\n",
      "Epoch 7 Batch 100 Loss 0.1361\n",
      "Epoch 7 Batch 200 Loss 0.1446\n",
      "Epoch 7 Batch 300 Loss 0.1376\n",
      "Epoch 7 Batch 400 Loss 0.1569\n",
      "Epoch 7 Batch 500 Loss 0.1398\n",
      "Epoch 7 Batch 600 Loss 0.1404\n",
      "Epoch 7 Batch 700 Loss 0.1456\n",
      "Epoch 7 Batch 800 Loss 0.1613\n",
      "Epoch 7 Batch 900 Loss 0.1646\n",
      "Epoch 7 Batch 1000 Loss 0.1522\n",
      "Epoch 7 Batch 1100 Loss 0.1433\n",
      "Time taken for 1 epoch 320.52941823005676 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1226\n",
      "Epoch 8 Batch 100 Loss 0.1239\n",
      "Epoch 8 Batch 200 Loss 0.1182\n",
      "Epoch 8 Batch 300 Loss 0.1496\n",
      "Epoch 8 Batch 400 Loss 0.1309\n",
      "Epoch 8 Batch 500 Loss 0.1208\n",
      "Epoch 8 Batch 600 Loss 0.1272\n",
      "Epoch 8 Batch 700 Loss 0.1396\n",
      "Epoch 8 Batch 800 Loss 0.1283\n",
      "Epoch 8 Batch 900 Loss 0.1345\n",
      "Epoch 8 Batch 1000 Loss 0.1268\n",
      "Epoch 8 Batch 1100 Loss 0.1380\n",
      "Time taken for 1 epoch 320.3428945541382 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1182\n",
      "Epoch 9 Batch 100 Loss 0.1150\n",
      "Epoch 9 Batch 200 Loss 0.1125\n",
      "Epoch 9 Batch 300 Loss 0.1225\n",
      "Epoch 9 Batch 400 Loss 0.1204\n",
      "Epoch 9 Batch 500 Loss 0.1092\n",
      "Epoch 9 Batch 600 Loss 0.1118\n",
      "Epoch 9 Batch 700 Loss 0.1422\n",
      "Epoch 9 Batch 800 Loss 0.1250\n",
      "Epoch 9 Batch 900 Loss 0.1300\n",
      "Epoch 9 Batch 1000 Loss 0.1333\n",
      "Epoch 9 Batch 1100 Loss 0.1577\n",
      "Time taken for 1 epoch 320.4113118648529 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1178\n",
      "Epoch 10 Batch 100 Loss 0.0902\n",
      "Epoch 10 Batch 200 Loss 0.1139\n",
      "Epoch 10 Batch 300 Loss 0.1215\n",
      "Epoch 10 Batch 400 Loss 0.1104\n",
      "Epoch 10 Batch 500 Loss 0.1476\n",
      "Epoch 10 Batch 600 Loss 0.0949\n",
      "Epoch 10 Batch 700 Loss 0.1239\n",
      "Epoch 10 Batch 800 Loss 0.1372\n",
      "Epoch 10 Batch 900 Loss 0.1112\n",
      "Epoch 10 Batch 1000 Loss 0.1151\n",
      "Epoch 10 Batch 1100 Loss 0.1255\n",
      "Time taken for 1 epoch 321.12935423851013 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0928\n",
      "Epoch 11 Batch 100 Loss 0.1046\n",
      "Epoch 11 Batch 200 Loss 0.0991\n",
      "Epoch 11 Batch 300 Loss 0.1040\n",
      "Epoch 11 Batch 400 Loss 0.1094\n",
      "Epoch 11 Batch 500 Loss 0.1184\n",
      "Epoch 11 Batch 600 Loss 0.1127\n",
      "Epoch 11 Batch 700 Loss 0.1156\n",
      "Epoch 11 Batch 800 Loss 0.1088\n",
      "Epoch 11 Batch 900 Loss 0.1162\n",
      "Epoch 11 Batch 1000 Loss 0.1133\n",
      "Epoch 11 Batch 1100 Loss 0.1074\n",
      "Time taken for 1 epoch 321.19294023513794 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1086\n",
      "Epoch 12 Batch 100 Loss 0.1125\n",
      "Epoch 12 Batch 200 Loss 0.1138\n",
      "Epoch 12 Batch 300 Loss 0.1104\n",
      "Epoch 12 Batch 400 Loss 0.1153\n",
      "Epoch 12 Batch 500 Loss 0.1314\n",
      "Epoch 12 Batch 600 Loss 0.1020\n",
      "Epoch 12 Batch 700 Loss 0.1198\n",
      "Epoch 12 Batch 800 Loss 0.1339\n",
      "Epoch 12 Batch 900 Loss 0.1117\n",
      "Epoch 12 Batch 1000 Loss 0.1148\n",
      "Epoch 12 Batch 1100 Loss 0.1217\n",
      "Time taken for 1 epoch 320.0389795303345 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1062\n",
      "Epoch 13 Batch 100 Loss 0.1043\n",
      "Epoch 13 Batch 200 Loss 0.1063\n",
      "Epoch 13 Batch 300 Loss 0.0997\n",
      "Epoch 13 Batch 400 Loss 0.1108\n",
      "Epoch 13 Batch 500 Loss 0.1105\n",
      "Epoch 13 Batch 600 Loss 0.1156\n",
      "Epoch 13 Batch 700 Loss 0.1055\n",
      "Epoch 13 Batch 800 Loss 0.1067\n",
      "Epoch 13 Batch 900 Loss 0.1150\n",
      "Epoch 13 Batch 1000 Loss 0.1293\n",
      "Epoch 13 Batch 1100 Loss 0.1103\n",
      "Time taken for 1 epoch 319.6529173851013 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1012\n",
      "Epoch 14 Batch 100 Loss 0.1082\n",
      "Epoch 14 Batch 200 Loss 0.0943\n",
      "Epoch 14 Batch 300 Loss 0.1102\n",
      "Epoch 14 Batch 400 Loss 0.1104\n",
      "Epoch 14 Batch 500 Loss 0.1064\n",
      "Epoch 14 Batch 600 Loss 0.0995\n",
      "Epoch 14 Batch 700 Loss 0.1123\n",
      "Epoch 14 Batch 800 Loss 0.1156\n",
      "Epoch 14 Batch 900 Loss 0.1045\n",
      "Epoch 14 Batch 1000 Loss 0.1123\n",
      "Epoch 14 Batch 1100 Loss 0.1107\n",
      "Time taken for 1 epoch 320.1940824985504 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0888\n",
      "Epoch 15 Batch 100 Loss 0.0978\n",
      "Epoch 15 Batch 200 Loss 0.0960\n",
      "Epoch 15 Batch 300 Loss 0.0960\n",
      "Epoch 15 Batch 400 Loss 0.1086\n",
      "Epoch 15 Batch 500 Loss 0.1088\n",
      "Epoch 15 Batch 600 Loss 0.1105\n",
      "Epoch 15 Batch 700 Loss 0.0950\n",
      "Epoch 15 Batch 800 Loss 0.1015\n",
      "Epoch 15 Batch 900 Loss 0.1021\n",
      "Epoch 15 Batch 1000 Loss 0.1390\n",
      "Epoch 15 Batch 1100 Loss 0.1045\n",
      "Time taken for 1 epoch 320.7831082344055 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0875\n",
      "Epoch 16 Batch 100 Loss 0.0968\n",
      "Epoch 16 Batch 200 Loss 0.0989\n",
      "Epoch 16 Batch 300 Loss 0.0992\n",
      "Epoch 16 Batch 400 Loss 0.0981\n",
      "Epoch 16 Batch 500 Loss 0.0985\n",
      "Epoch 16 Batch 600 Loss 0.1132\n",
      "Epoch 16 Batch 700 Loss 0.1095\n",
      "Epoch 16 Batch 800 Loss 0.1177\n",
      "Epoch 16 Batch 900 Loss 0.1113\n",
      "Epoch 16 Batch 1000 Loss 0.1127\n",
      "Epoch 16 Batch 1100 Loss 0.1262\n",
      "Time taken for 1 epoch 320.34074330329895 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0937\n",
      "Epoch 17 Batch 100 Loss 0.0967\n",
      "Epoch 17 Batch 200 Loss 0.0981\n",
      "Epoch 17 Batch 300 Loss 0.1092\n",
      "Epoch 17 Batch 400 Loss 0.1021\n",
      "Epoch 17 Batch 500 Loss 0.1190\n",
      "Epoch 17 Batch 600 Loss 0.0933\n",
      "Epoch 17 Batch 700 Loss 0.1127\n",
      "Epoch 17 Batch 800 Loss 0.0990\n",
      "Epoch 17 Batch 900 Loss 0.1081\n",
      "Epoch 17 Batch 1000 Loss 0.1059\n",
      "Epoch 17 Batch 1100 Loss 0.0964\n",
      "Time taken for 1 epoch 319.94823575019836 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.1017\n",
      "Epoch 18 Batch 100 Loss 0.0914\n",
      "Epoch 18 Batch 200 Loss 0.0907\n",
      "Epoch 18 Batch 300 Loss 0.0947\n",
      "Epoch 18 Batch 400 Loss 0.1065\n",
      "Epoch 18 Batch 500 Loss 0.1028\n",
      "Epoch 18 Batch 600 Loss 0.1037\n",
      "Epoch 18 Batch 700 Loss 0.1039\n",
      "Epoch 18 Batch 800 Loss 0.0962\n",
      "Epoch 18 Batch 900 Loss 0.1014\n",
      "Epoch 18 Batch 1000 Loss 0.0932\n",
      "Epoch 18 Batch 1100 Loss 0.1009\n",
      "Time taken for 1 epoch 319.760240316391 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0934\n",
      "Epoch 19 Batch 100 Loss 0.0988\n",
      "Epoch 19 Batch 200 Loss 0.0983\n",
      "Epoch 19 Batch 300 Loss 0.0939\n",
      "Epoch 19 Batch 400 Loss 0.0960\n",
      "Epoch 19 Batch 500 Loss 0.1068\n",
      "Epoch 19 Batch 600 Loss 0.1163\n",
      "Epoch 19 Batch 700 Loss 0.1139\n",
      "Epoch 19 Batch 800 Loss 0.1008\n",
      "Epoch 19 Batch 900 Loss 0.1064\n",
      "Epoch 19 Batch 1000 Loss 0.1240\n",
      "Epoch 19 Batch 1100 Loss 0.1056\n",
      "Time taken for 1 epoch 319.9855110645294 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0889\n",
      "Epoch 20 Batch 100 Loss 0.0924\n",
      "Epoch 20 Batch 200 Loss 0.0963\n",
      "Epoch 20 Batch 300 Loss 0.1092\n",
      "Epoch 20 Batch 400 Loss 0.0928\n",
      "Epoch 20 Batch 500 Loss 0.0999\n",
      "Epoch 20 Batch 600 Loss 0.1038\n",
      "Epoch 20 Batch 700 Loss 0.1021\n",
      "Epoch 20 Batch 800 Loss 0.1027\n",
      "Epoch 20 Batch 900 Loss 0.1135\n",
      "Epoch 20 Batch 1000 Loss 0.1057\n",
      "Epoch 20 Batch 1100 Loss 0.0948\n",
      "Time taken for 1 epoch 320.3719403743744 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0900\n",
      "Epoch 21 Batch 100 Loss 0.0891\n",
      "Epoch 21 Batch 200 Loss 0.0923\n",
      "Epoch 21 Batch 300 Loss 0.1007\n",
      "Epoch 21 Batch 400 Loss 0.1028\n",
      "Epoch 21 Batch 500 Loss 0.1068\n",
      "Epoch 21 Batch 600 Loss 0.1070\n",
      "Epoch 21 Batch 700 Loss 0.0980\n",
      "Epoch 21 Batch 800 Loss 0.1124\n",
      "Epoch 21 Batch 900 Loss 0.1105\n",
      "Epoch 21 Batch 1000 Loss 0.1061\n",
      "Epoch 21 Batch 1100 Loss 0.1109\n",
      "Time taken for 1 epoch 321.13694858551025 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0918\n",
      "Epoch 22 Batch 100 Loss 0.0904\n",
      "Epoch 22 Batch 200 Loss 0.0818\n",
      "Epoch 22 Batch 300 Loss 0.0943\n",
      "Epoch 22 Batch 400 Loss 0.0994\n",
      "Epoch 22 Batch 500 Loss 0.0988\n",
      "Epoch 22 Batch 600 Loss 0.0997\n",
      "Epoch 22 Batch 700 Loss 0.0983\n",
      "Epoch 22 Batch 800 Loss 0.1025\n",
      "Epoch 22 Batch 900 Loss 0.1027\n",
      "Epoch 22 Batch 1000 Loss 0.1172\n",
      "Epoch 22 Batch 1100 Loss 0.0914\n",
      "Time taken for 1 epoch 320.49899411201477 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0948\n",
      "Epoch 23 Batch 100 Loss 0.1074\n",
      "Epoch 23 Batch 200 Loss 0.0937\n",
      "Epoch 23 Batch 300 Loss 0.0925\n",
      "Epoch 23 Batch 400 Loss 0.0982\n",
      "Epoch 23 Batch 500 Loss 0.0911\n",
      "Epoch 23 Batch 600 Loss 0.1037\n",
      "Epoch 23 Batch 700 Loss 0.0962\n",
      "Epoch 23 Batch 800 Loss 0.1093\n",
      "Epoch 23 Batch 900 Loss 0.0976\n",
      "Epoch 23 Batch 1000 Loss 0.0916\n",
      "Epoch 23 Batch 1100 Loss 0.0988\n",
      "Time taken for 1 epoch 320.4395229816437 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0905\n",
      "Epoch 24 Batch 100 Loss 0.0874\n",
      "Epoch 24 Batch 200 Loss 0.0957\n",
      "Epoch 24 Batch 300 Loss 0.0866\n",
      "Epoch 24 Batch 400 Loss 0.1038\n",
      "Epoch 24 Batch 500 Loss 0.0922\n",
      "Epoch 24 Batch 600 Loss 0.0891\n",
      "Epoch 24 Batch 700 Loss 0.1001\n",
      "Epoch 24 Batch 800 Loss 0.1033\n",
      "Epoch 24 Batch 900 Loss 0.1054\n",
      "Epoch 24 Batch 1000 Loss 0.1110\n",
      "Epoch 24 Batch 1100 Loss 0.1110\n",
      "Time taken for 1 epoch 319.8584384918213 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0932\n",
      "Epoch 25 Batch 100 Loss 0.0909\n",
      "Epoch 25 Batch 200 Loss 0.0809\n",
      "Epoch 25 Batch 300 Loss 0.0852\n",
      "Epoch 25 Batch 400 Loss 0.0965\n",
      "Epoch 25 Batch 500 Loss 0.0954\n",
      "Epoch 25 Batch 600 Loss 0.0999\n",
      "Epoch 25 Batch 700 Loss 0.1001\n",
      "Epoch 25 Batch 800 Loss 0.1004\n",
      "Epoch 25 Batch 900 Loss 0.1011\n",
      "Epoch 25 Batch 1000 Loss 0.0967\n",
      "Epoch 25 Batch 1100 Loss 0.1073\n",
      "Time taken for 1 epoch 320.4325292110443 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize Model\n",
    "\n",
    "encoder3 = Encoder(len(en_tokenizer.word_index)+1, 300, 256)\n",
    "decoder3 = Decoder(len(ita_tokenizer.word_index)+1, 300, 256, 'concat')\n",
    "en_initial_states = encoder3.init_states(128)\n",
    "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
    "\n",
    "#Train Step\n",
    "@tf.function\n",
    "def train_step3(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder3(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_state_h, de_state_c = en_states\n",
    "\n",
    "        # We need to create a loop to iterate through the target sequences\n",
    "        for i in range(target_seq_out.shape[1]):\n",
    "            # Input to the decoder must have shape of (batch_size, length)\n",
    "            # so we need to expand one dimension\n",
    "            decoder_in = tf.expand_dims(target_seq_in[:, i], 1)\n",
    "            logit, de_state_h, de_state_c, _ = decoder3(\n",
    "                decoder_in, de_state_h, de_state_c, en_outputs[0])\n",
    "\n",
    "            # The loss is now accumulated through the whole batch\n",
    "            loss += loss_func(target_seq_out[:, i], logit)\n",
    "\n",
    "    #Gradient Update\n",
    "    variables = encoder3.trainable_variables + decoder3.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss / target_seq_out.shape[1]\n",
    "\n",
    "import time\n",
    "for e in range(25):\n",
    "  start = time.time()\n",
    "  #Saving Weights\n",
    "  encoder3.save_weights(\n",
    "            '/content/drive/My Drive/Attention Models/saved_model/Check3/Encoder/encoder_{}.h5'.format(e + 1))\n",
    "  decoder3.save_weights(\n",
    "            '/content/drive/My Drive/Attention Models/saved_model/Check3/Decoder/decoder_{}.h5'.format(e + 1))\n",
    "  for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "    loss = train_step3(source_seq, target_seq_in,\n",
    "                              target_seq_out, en_initial_states)\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(e +  1, batch, loss.numpy()))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06Pe90ORKZFm"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Predicting(Translating) Sentence\n",
    "def predict3(i):\n",
    "  en_out, state_h, state_c = encoder3(data_en[i:i+1],encoder.init_states(1))\n",
    "  eng = [en_tokenizer.index_word[idx] for idx in data_en[i:i+1][0] if idx !=0]\n",
    "  ita = [ita_tokenizer.index_word[idx] for idx in data_ita_in[i:i+1][0] \n",
    "                                    if idx !=0 \n",
    "                                        and ita_tokenizer.index_word[idx]!='<start>']\n",
    "  vec = np.array(ita_tokenizer.word_index['<start>']).reshape(1,1)\n",
    "  out = []\n",
    "  weights = []\n",
    "  while(50):  \n",
    "    de_out, state_h,state_c, w = decoder3(vec, state_h, state_c, en_out)\n",
    "    vec = np.argmax(de_out[0][0]).reshape(1,1)\n",
    "    if ita_tokenizer.index_word[np.argmax(de_out[0][0])] == '<end>':\n",
    "      break\n",
    "    out.append(ita_tokenizer.index_word[np.argmax(de_out[0][0])])\n",
    "    weights.append(list(w[0][0].numpy()))\n",
    "\n",
    "  print(\"English:             \",' '.join(eng))\n",
    "  print(\"Translated(italian): \",' '.join(out))\n",
    "\n",
    "  plot_attention(np.array(weights), eng, out)\n",
    "  return ita, out\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention[:,0:len(sentence)], cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "colab_type": "code",
    "id": "1bog8VEGKjnz",
    "outputId": "574ce7b5-d493-4a69-bdb9-7e149f58dca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:              are you brave ?\n",
      "Translated(italian):  sei coraggiosa ?\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita, out = predict3(11199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "1kQA-VlrNyIW",
    "outputId": "dd4fa9df-4c8c-4d84-bd7b-49680ee5bb60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:              thanks for your concern .\n",
      "Translated(italian):  grazie per il vostro interesse .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita, out = predict3(134499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "colab_type": "code",
    "id": "iBBnRKPmN7gR",
    "outputId": "42f4be40-1cbe-46bd-d956-089c509800b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:              i feel so much better .\n",
      "Translated(italian):  mi sento molto meglio .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ita , out = predict3(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qxoMknBBHtwO",
    "outputId": "494ea33a-aaa4-4b9b-a88c-e85db0f22b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  mi sento molto meglio .\n",
      "Prediction:  mi sento molto meglio .\n",
      "Bleu-score:  0.668740304976422\n"
     ]
    }
   ],
   "source": [
    "#Bleu-Score for Concat-Score Model\n",
    "\n",
    "print(\"Target: \",' '.join(ita))\n",
    "print(\"Prediction: \",' '.join(out))\n",
    "score = sentence_bleu(ita, out)\n",
    "print(\"Bleu-score: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlUsM6N8R15Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "go-RhAx8SEV2"
   },
   "source": [
    "**Final Observation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUAteeLgSKiE"
   },
   "source": [
    "**Encoder:**  Here in Attention We takes Simple Encoder Architecture \n",
    "\n",
    "**Decoder:**  But Here in Decoder Layer We have slightly Different Architecture With Attention Mechanism\n",
    "\n",
    "In This Assignment We applied One Step Decoder Which Apply Attention Mechanism and Decoder Block Step by Step for Each Time-stamp..\n",
    "So Basically, Vanila Encoder-Decoder Can not work Excellently when Machine Translation Task contains Long Sequences....\n",
    "that's Why Attention Based Mechanism Comes in Picture, Attention Layer Finds the Word from Input Space which help alot to translate the word in other Language for specific Timestamp by Calculating the Score\n",
    "\n",
    "In this Assignment we used Luong - Style Attention Which is very similar to Bahadanau Attention But one thing is differnt is the Method of Calculating Score for Global Attention which we can see by reading this Paper..\n",
    "https://arxiv.org/pdf/1508.04025.pdf\n",
    "\n",
    "So Luong-style Attention have the three Scoring Methods\n",
    "1) Dot-Score\n",
    "2) General-Score\n",
    "3) Concat-Score\n",
    "\n",
    "After Applying the All three score in Training Process we used The BLEU Score for Evaluation Process .\n",
    "\n",
    "We got same Bleu- Score  Aroung --> 0.61 in Case of applying Dot and General Score in Attention Mechanism  But with Concat Score we get slighty good BLUE Result --> 0.6687 \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "smitkumbhani080@gmail.com_24.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "48c87962dbbf4fc89f701b4ffb6da3c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53a79102dcc3402fa588ae20cd429833": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "876fb3be29634e17836820d516432318": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b72eb119c830402091b33289ecd31b57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48c87962dbbf4fc89f701b4ffb6da3c0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9827b3313214c20b0adedf22b882961",
      "value": 1
     }
    },
    "cf4c373ea6e44c7cb5267ab731c476bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b72eb119c830402091b33289ecd31b57",
       "IPY_MODEL_db6f34ab19894f229a9d35b969f04cf7"
      ],
      "layout": "IPY_MODEL_876fb3be29634e17836820d516432318"
     }
    },
    "db6f34ab19894f229a9d35b969f04cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd32e8c2404f40bca1b3da96c020472f",
      "placeholder": "",
      "style": "IPY_MODEL_53a79102dcc3402fa588ae20cd429833",
      "value": " 336614/? [00:16&lt;00:00, 20975.73it/s]"
     }
    },
    "dd32e8c2404f40bca1b3da96c020472f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9827b3313214c20b0adedf22b882961": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
